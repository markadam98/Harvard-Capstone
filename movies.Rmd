---
title: "Predicting Movie Ratings"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---


In the first code chunk I loaded the libraries.  Throughout this project I had a lot of trouble getting the data loaded.  R Studio would frequently time out or run out of memory, due the size of the files.  Therefore, once I got initial code successfully loaded as a dataframe, I saved it in an Excel csv file to my hard drive, and then loaded that file directly from my hard drive to R studio each time I worked on this project.  The bottomline is I am staring with the code to build the dataframe as provided in the instructions. 

```{r libraries and data, message=FALSE }
library(tidyverse)
library(caret)
library(data.table)
library(stringr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(outliers)
library(knitr)
library(rmarkdown)
edx <- read.csv("C:/Users/Mark/Documents/Harvard Captstone/edx.csv")
validation <- read.csv("C:/Users/Mark/Documents/Harvard Captstone/validation.csv")

```


## Movie Data
### Observe the data
1. Print the head of the training set edx.
2. Movies can fall into one or more genres.  I looked at how many unique entries there are in the genres column, which is the number of combinations of genres.  I got 797.  This is too many to treat as a categorical variable or to create binary variables for each of the 797 values.  
3. Therefore, I looked at how many individual genres there are. There are 19 genres plus an extra category of "(no genres listed)".  There are only 7 "no genres listed" they apply to a single movie, so I treated it as insignificant.  
3. I also notice the timestamp of when the movie was rated is meaningless the human eye.
4. The year of release is important information because there might be a trend in how people rate movies, or perhaps a movie rated decades after release may be an indication it is a classic. 
```{r EDA}
# First 6 rows of edx
print(head(edx))

# Dimension of edx
print('The dimensions of the date set are as follows: ')
print(dim(edx))
cat("\n")

# Number of distinct Users
print(paste("Number of distinct users: ", length(unique(edx$userId))))
cat("\n")
# Number of distinct Movies
print(paste("Number of distinct movies: ", length(unique(edx$movieId))))
cat("\n")
# Number a unique genre value in the genres column 
uni_gens <- unique(edx$genres)
num_gen_value <- length(uni_gens)
print(paste("The total number of unique values in the genres column is", num_gen_value, '.  That is way to many to treat as a categorical variable.'))
cat("\n")

#Distinct genres 
gen_split <- str_split(edx$genres, "\\|")
gen_char2 <- unlist(gen_split)
uni <- unique(gen_char2)
print(paste("Total unique genres is", length(uni), '.  Acutally, there are only 19 because we will not count (no genres listed)'))
print(uni)
cat('\n')

print('Here are the ratings with no genre listed.  There only 7 ratings covering a single movie')
edx %>% filter(genres== '(no genres listed)')
```
### Historgrams of users and movies
Here are the histograms for the number of reviews per user and number of reviews made for each movie.  They are not very useful, but a good opportunity to demonstrate the usefulness of the log10 scale.  
```{r histograms of users and movies, message=FALSE}
edx %>% group_by(userId)%>%summarize(n = n()) %>% ggplot(aes(x=n)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +ggtitle('Distribtion of how many reviews each user made')+xlab("Number of reviews of each user")

edx %>% group_by(movieId)%>%summarize(n = n()) %>% ggplot(aes(x=n)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) + ggtitle('Distribtion of how many reviews each movie received')+xlab("Number of reviews for each movier")
```

Here is is the same histogram but with density of counts vice the number of counts.  I also added the density line. Again this is not very helpful.
```{r same histograms with density, warning=FALSE, message=FALSE}

edx %>% group_by(userId)%>%summarize(n = n()) %>% ggplot(aes(x=n, y=..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +geom_density(col='red')+ggtitle('Distribtion of how many reviews each user made')+xlab("Number of reviews of each user")

edx %>% group_by(movieId)%>%summarize(n = n()) %>% ggplot(aes(x=n, y=..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +geom_density(col='red')+ggtitle('Distribtion of how many reviews each movie received')+xlab("Number of reviews for each movie")
```



Here are the same histograms with the x axis on the log10 scale.  This is much easier to interpret.  Personally I am partial to histograms with density, although in this case for some reason I find the counts slightly more interesting.  

```{r histograms with log scaled x axis, warning=FALSE, message=FALSE}
edx %>% group_by(userId)%>%summarize(n = n()) %>% ggplot(aes(x=n)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +ggtitle('Distribtion of how many reviews each movie received')+xlab("Number of reviews for each movier")+scale_x_log10()

edx %>% group_by(movieId)%>%summarize(n = n()) %>% ggplot(aes(x=n)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20)+ggtitle('Distribtion of how many reviews each movie received')+xlab("Number of reviews for each movier")+scale_x_log10()
```
Here is the same histogram with the x axis on the log scale but with density vice count.  
```{r histograms with log scaled x axis and density, warning=FALSE, message=FALSE}

edx %>% group_by(userId)%>%summarize(n = n()) %>% ggplot(aes(x=n, y=..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +geom_density(col='red')+ggtitle('Distribtion of how many reviews each user made')+xlab("Number of reviews of each user")+ scale_x_log10()

edx %>% group_by(movieId)%>%summarize(n = n()) %>% ggplot(aes(x=n, y=..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins = 20) +geom_density(col='red')+ggtitle('Distribtion of how many reviews each movie received')+xlab("Number of reviews for each movier")+scale_x_log10()

```
### Wrangling
1. Convert the time stamp to the year the movie was rated
2. Using the extract function, I separated the year released from the title into two separate columns.  Note:  The separate funciton would also work here but for some reason the extract function liked my regex sequence better.
3. Convert year released from a string to a numeric
4. Create a new column, released_to_rated, that measures the time in year from the release of the movie until the time it was rated.
5. Delete the original timestamp column.
6. Group the data so each movie only takes one entry, and get the total number of ratings for each movie, the average rating, and the average time from release data to the date each movie was rated.  The latter one could be important if for example, movies become classics and are rated decades after their release.  I would expect to see a positive correlation such that movies rated long after their release data are rated higher on average than movies with shorter spans between release date and date of rating.  
7. See what the date set looks like now.

```{r wrangling part I, warning=FALSE}
edx1 <-  edx %>% mutate( year_rated = year(as_datetime(timestamp))) %>% 
  extract(col=title, into = c('title', 'year_released'), regex = "(.+)\\((\\d{4})") %>% 
  mutate(year_released = as.numeric(year_released)) %>%
  mutate(released_to_rated = year_rated - year_released) %>% select(-timestamp)


edx2 <- edx1 %>% group_by(title, movieId, genres, year_released) %>% summarize(num_of_ratings=n(),  avg_rate = round(mean(rating),2), 
              avg_time_to_rate = round(mean(released_to_rated),2))

head(edx2)
```

### Making sure the years are correct
Some movies contain 4 digit numbers in the title that could potentially be confused with the date provided.  For example, the movie "Murder at 1600 (1997)".  I want to make sure I extracted 1997 as the date and not 1600.  I am going to run a grubbs test.  As long as I don't see outliers earlier than the early 1900s, my regex should be okay.  

In the grubbs test below, I only see one outlier, for a movie released in 1915. I confirmed this movie does exist.  It is called "The Birth of a Nation'.  

Also, we see a p-value of .82.  This means it is very unlikely the data set is normal.  We would expect this because the production of movies steadily increased from 1915, so we won't get the bell curve.  The histogram does sow a progressive increase, although there have been some notable drops such as in the early 1990s and in the last bin of the histogram.  While I can't explain that, it doesn't give me any reason to think there is something wrong with data.  

```{r outliers }
print(grubbs.test(edx2$year_released))
print(filter(edx2, year_released==1915))

edx2 %>% ggplot(aes(x=year_released)) + geom_histogram(color = 'gray', fill = 'steelblue', bins=50) +
  ggtitle('Distribution of years movies were released')
```


### Wrangling Continues
I am liking it better, but I still want to make a few more adjustments.
1. The groupby function outputs a matrix so I want to get this back in the dataframe format.
2. I am interested in the number of genres.  A movie that touches several genres may appeal to a larger audience than a movie with just one genre, so this could impact that rating.  I counted the pipes and added one.  For example, a single genre has no pipes, so that is 0 + 1 = 1 genre.  
3. I scaled the number of ratings, average time from release to rating, year released and number of genres.  
4. Then I binded the unscaled columns, the scaled columns, and the output column (average rating)

```{r wrangling part II}
edx3 <- as.data.frame(edx2) %>% mutate(num_of_genres = str_count(edx2$genres, pattern = "\\|") +1)

edx_scale <- scale(edx3[c(4:5, 7:8)])
edx4 <- cbind(edx3[, c(1:3)], edx_scale, edx3['avg_rate'])        
head(edx4)

```

### Histograms of Total Ratings and Average Ratings
This moderately informative, but very interesting to see how most users preferred to give a rating as a whole number vice half.  Look at any whole number and it has more ratings than does a rating of .5 greater or .5 less.  However, when we look at the distributions of the average ratings we start to see an almost normal shaped histogram.  Notable, the most common rating converges around the bin centered on 3.5, and you also see the number 5 ratings go way down when compared to the total.  A lot of individual users have out 5s, but rarely does a movie have an average rating of 5 when rated by multiple users.  

I included both the count and density versions of each histogram.  

```{r histograms of ratings, warning=FALSE, message=FALSE}

edx %>% ggplot(aes(x=rating, y= ..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins=10) + ggtitle('Distribution of the all ratings of all movies')

edx %>% ggplot(aes(x=rating)) + geom_histogram(color = 'gray', fill = 'steelblue', bins=10) +
  ggtitle('Distribution of all ratings of all movies')


edx4 %>% ggplot(aes(x=avg_rate)) + geom_histogram(color = 'gray', fill = 'steelblue', bins =10) + 
  ggtitle('Distribution of the average rating of each movie')

edx4 %>% ggplot(aes(x=avg_rate, y= ..density..)) + geom_histogram(color = 'gray', fill = 'steelblue', bins =10) + 
  ggtitle('Distribution of the average rating of each movie')+geom_density(col='red')

```



### Linear regression model

```{r run an lm model}
model <- lm(avg_rate~year_released + num_of_ratings + num_of_genres + avg_time_to_rate, edx4)
summary(model)
y_hat <- predict(model, edx4)

rmse <- sqrt(mean((y_hat - edx4$avg_rate)^2, na.rm = TRUE))

print(paste('RMSE = ', round(rmse,2)))

```
By looking at the R-squared, we know this is not a good model, but can we tell anything from it?
1. Year released:  The p-value shows this is significant.  With a coefficient of .43, this tells us that movie ratings tend to trend upward over the years.  We don't know if movies got better or people just rated more generously over the years.
2. Number of ratings.  While the coefficient is small, we see small positive trend for movies with a higher number or ratings.  A movie with a lot of ratings may indicate it is a popular movie.  
3. Number of genres.  The p-value of .45 tells us this predictors likely not significant.  And even it is, the coefficient is very small.  
4. Avg time from release to rating.  This is the most significant predictor.  Good movies tend to get watched decades after release.  

We got an RMSE of .54 when calculated manually, the same as the residual standard error the model.  

### Looking at each genre as a binary value
The number of genres in each movie's classification turned out to be a insignificant.  But what if each genre got it's own column and was represented by a binary variable, 1 if the movie contains that genre and 0 otherwise.  

I removed no genres listed from the model.  
```{r add columns for each individual genre}
edx4 <- edx3 %>% mutate(Drama = as.numeric(str_detect(genres, "Drama")), Animation = as.numeric(str_detect(genres, "Animation")),
                        Children = as.numeric(str_detect(genres, "Children")),
                        Musical = as.numeric(str_detect(genres, "Musical")),
                        Thriller = as.numeric(str_detect(genres, "Thriller")),
                        Action = as.numeric(str_detect(genres, "Action")),
                        Adventure = as.numeric(str_detect(genres, "Adventure")),
                        Sci_Fi = as.numeric(str_detect(genres, "Sci-Fi")),
                        War = as.numeric(str_detect(genres, "War")),
                        Fantasy = as.numeric(str_detect(genres, "Fantasy")),
                        Horror = as.numeric(str_detect(genres, "Horror")),
                        Romance = as.numeric(str_detect(genres, "Romance")),
                        Comedy = as.numeric(str_detect(genres, "Comedy")),
                        Crime = as.numeric(str_detect(genres, "Crime")),
                        Western = as.numeric(str_detect(genres, "Western")),
                        Mystery = as.numeric(str_detect(genres, "Mystery")),
                        IMAX = as.numeric(str_detect(genres, "IMAX")),
                        Documentary = as.numeric(str_detect(genres, "Documentary")),
                        Film_Noir = as.numeric(str_detect(genres, "Film-Noir")))
head(edx4)
edx5 <- cbind(edx_scale, edx4[, 9:27], edx4['avg_rate'])
head(edx5)
model2 <- lm(avg_rate ~ ., edx5)
summary(model2)

y_hat2 <- predict(model2, edx5)

rmse2 <- sqrt(mean((y_hat2 - edx5$avg_rate)^2, na.rm = TRUE))

print(paste('RMSE = ', round(rmse2,2)))

```
The R-squared (higher) and RMSE (lower) are both a little better than the previous model.  However the p-values for each genre tend to be very high so it is not clear if we can say any of the binary genres are significant.  Documentary is the only one with a positive value, but the p-value is .81, so this is not reliable.  Also, the intercept is higher, which is what the remaining coefficients are negative.  The intercept at 3.8 is higher than the overall average rating of 3.2.  With the exception of documentary, each additional genre is going to reduce the predicted output.  This indicates to me that more genres reduce the rating.  Perhaps a viewer wants to see a comedy, but sees a comedy|horror combination and doesn't like the horror aspect.  Likewise, a horror enthusiast sees the movie hoping to see a horror film, but is disappointed with the comedy aspect.  

## Apply the models to the validation set
### First apply the same wrangling and data manipulations to the validation set
```{r wrangling the validation, warning=FALSE, message=FALSE}
val1 <-  validation %>% mutate( year_rated = year(as_datetime(timestamp))) %>% 
  extract(col=title, into = c('title', 'year_released'), regex = "(.+)\\((\\d{4})") %>% 
  mutate(year_released = round(as.numeric(year_released),2)) %>%
  mutate(released_to_rated = year_rated - year_released) %>% select(-timestamp)

val2 <- val1 %>% group_by(title, movieId, genres) %>% summarize(num_of_ratings=n(),  avg_rate = round(mean(rating),2), 
                avg_time_to_rate = round(mean(released_to_rated),2), year_released = mean(year_released) )

head(val2)

val3 <- as.data.frame(val2) %>% mutate(num_of_genres = str_count(val2$genres, pattern = "\\|") +1)

val_scale <- scale(val3[c(4, 6:8)])
val4 <- cbind(val3[, c(1:3)], val_scale, val3['avg_rate'])        

head(val4)
```

### Run the model and compare the prediction
```{r}
y_hat <- predict(model, val4)

val_rmse <- sqrt(mean((y_hat - val4$avg_rate)^2, na.rm = TRUE))
print(paste('The RMSE for the first model is', round(val_rmse,2)))
print("We got .54 on the training set.  While there is an expectation that the model will perform better on the training data than it will on previously unseen data, the diference between .54 and .65 is somewhat concerning.  At least we know the model as a poor R^2 which doesn't which tell us the model doesn't not explain the data very well.  Therefore it is not surprising that our model performs signficantly worse on the test data as it does on the training data" )
```
### Encode binary variables for each individual genre in the validation set
``` {r encode binary variables for validation set}
val4 <- val3 %>% mutate(Drama = as.numeric(str_detect(genres, "Drama")), Animation = as.numeric(str_detect(genres, "Animation")),
                        Children = as.numeric(str_detect(genres, "Children")),
                        Musical = as.numeric(str_detect(genres, "Musical")),
                        Thriller = as.numeric(str_detect(genres, "Thriller")),
                        Action = as.numeric(str_detect(genres, "Action")),
                        Adventure = as.numeric(str_detect(genres, "Adventure")),
                        Sci_Fi = as.numeric(str_detect(genres, "Sci-Fi")),
                        War = as.numeric(str_detect(genres, "War")),
                        Fantasy = as.numeric(str_detect(genres, "Fantasy")),
                        Horror = as.numeric(str_detect(genres, "Horror")),
                        Romance = as.numeric(str_detect(genres, "Romance")),
                        Comedy = as.numeric(str_detect(genres, "Comedy")),
                        Crime = as.numeric(str_detect(genres, "Crime")),
                        Western = as.numeric(str_detect(genres, "Western")),
                        Mystery = as.numeric(str_detect(genres, "Mystery")),
                        IMAX = as.numeric(str_detect(genres, "IMAX")),
                        Documentary = as.numeric(str_detect(genres, "Documentary")),
                        Film_Noir = as.numeric(str_detect(genres, "Film-Noir")))
head(val4)
val5 <- cbind(val_scale, val4[, 9:27], val4['avg_rate'])
head(val5)
 
```
### Run the model with binary variables on the validation set

```{r run the model with binary variables on the validation set}

summary(model2)

y_hat2 <- predict(model2, val5)

val_rmse2 <- sqrt(mean((y_hat2 - val5$avg_rate)^2, na.rm = TRUE))
print(paste('Here we get', round(val_rmse2,2), "RMSE on the validation set.  Compare this to an RMSE of .48 on the training set.  Again we have a similar situation where the model doesn't fit the data well and we see relatively signficant differences in the training set RMSE and validation set RMSE."))
```
## Improving the model
### Look at aaverage rating per year

Data is a lot easier to visualize if it can be graphed on 2D plot, which means we can only use one predictor.  Here is the average rating of all movies released in each year.  I picked year of release the predictor because it had a positive coefficient and low p-value in the original model.  I included the smoothing lines for both a linear (yellow) and loess (red).  It doesn't need to follow the linear straight line.  I just included that to get an idea of the overall trend.  There appears to be no correlation until about 1950.  After 1950, we a clearer downward trend.  

```{r average rating per year, warnings = FALSE, message=FALSE}
edx1 %>% group_by(year_released) %>% summarize(avg_rate_per_year=mean(rating)) %>% ggplot(aes(year_released, avg_rate_per_year)) +
  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='loess') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+ ggtitle('Average rating per year')+
  labs(y='Average Rating', x="Year of Release")
```

When only considering movies after 1950 we can see a much clearer trend.  Likewise the R^2 jumps up to .74, and RMSE is considerable better, down to .1.  Recall we want the R^2 to increase and the RMSE to decrease.  This is actually starting to look like a good model.  But looks can be deceiving.  
```{r average rating per year from 1950, warning = FALSE, message=FALSE}

avg_rating_by_year_1950_or_later <- edx1%>% 
  filter(year_released>=1950) %>% group_by(year_released) %>% summarize(avg_rate_per_year=mean(rating)) 


avg_rating_by_year_1950_or_later  %>% ggplot(aes(year_released, avg_rate_per_year)) +
  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='loess') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+ ggtitle('Average rating per year')+
  labs(y='Average Rating', x="Year of Release")

post_1950_model <- lm(avg_rate_per_year ~ year_released, avg_rating_by_year_1950_or_later)
summary(post_1950_model)

y_hat_1950 <- predict(post_1950_model, avg_rating_by_year_1950_or_later)

rmse_1950 <- sqrt(mean((y_hat_1950 - avg_rating_by_year_1950_or_later$avg_rate_per_year)^2, na.rm = TRUE))
print(paste('The RMSE for the average rating per year for years after 1950 is', round(rmse_1950,4)))


```

The RMSE for the validation set is nearly the same, so we know the model performs well on the validation set.  But all the model is doing is predicting the average rating per year for years that we already have data on.  A better way to test this model is on unseen data in future years.  We see an overall downward trend, but with an upward trend in last years of the data.  So we don't know what is going to happen in future years. Furthermore, even if we could make an accurate prediction, all we are doing is predicting the average rating for all movies released in a single year.  I don't think that is useful information.  

```{r average rating per year post 1950, warning=FALSE, message=FALSE}
val_avg_rating_by_year_1950_or_later <- val1 %>% group_by(year_released) %>% summarize(avg_rate_per_year=mean(rating)) %>% 
  filter(year_released>=1950)

val_avg_rating_by_year_1950_or_later %>% ggplot(aes(year_released, avg_rate_per_year)) +  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='loess') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+ ggtitle('Average rating per year')+
  labs(y='Average Rating', x="Year of Release")

val_y_hat_1950 <- predict(post_1950_model, val_avg_rating_by_year_1950_or_later)

val_rmse_1950 <- sqrt(mean((val_y_hat_1950 -
              val_avg_rating_by_year_1950_or_later$avg_rate_per_year)^2, na.rm = TRUE))
print(paste('The RMSE for the average rating per year for years after 1950 in the validation set is is', round(val_rmse_1950,4)))

```

### Modeling the average rating based on the average time from release to rating

The the objective is to see if the average time from release to rating has an impact on the rating.  We do see pattern that that fits a loess regression line quite well.  However, I do see a couple of points that are below zero meaning the movie was rated before it was released.  Then towards the far end of the x axis, equating to about 85-90 years, the data points no longer fit the rest of the distribution.  Also, the first year a rating was recorded was 1995.  So for older movies most of the rating likely came from people watching classics.  Movies from the 1950s and 1960s that are still around in the mid-1990s are likely the classics that have withstood the test of time because the are deemed good movies by most viewers.  
```{r average time to rate, warning=FALSE, message=FALSE}

edx1 %>% group_by(released_to_rated) %>% summarize(avg_rating_by_avg_time_to_rate=mean(rating)) %>% 
  ggplot(aes(released_to_rated, avg_rating_by_avg_time_to_rate)) +
  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='auto') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+
  ggtitle('Average rating per average number of year from release to rating')+
  labs(y="Average Ratings", x= 'Average time in years from release date to time of rating')

```

### Wrangle the data a little more

Rating that occur before a movie is released is likely erroneous, so let's get rid of those points.  The last year a movie is released in the data set is 2008 and the last year of a rating was 2009.  If we back 60 years, this will include ratings made in 2009 of a movie made as late as 1949, but no earlier.  It is not perfect, but we will be able to fit this model to linear regression.  The linear (orange) line does a pretty good job of approximating the data.  The loess (red) line does better but it could be overfitting the modeling, so let's stick with the linear model.  Don't let perfect be the enemy of good.  

Now we see the R^2 and adjusted R^2 are above .9 and p-value shows the predictor, average time from release to rating, is indeed signficant.  

But what are we really learning here?  The longer a movie is watched after it is released tends to be rated highly.  I would say the opposite is true.  Because a movie is highly rated it tends to be watched longer after it release date.  Nonetheless this is an interesting trend.  

```{r average time from release to rate data wrangled, message=FALSE, warning=FALSE}

avg_rating_by_time_to_rate <- edx1 %>% filter((released_to_rated > 0) & released_to_rated < 60) %>%
          group_by(released_to_rated) %>%
          summarize(avg_rating_by_avg_time_to_rate=mean(rating)) 
      
avg_rating_by_time_to_rate  %>% ggplot(aes(released_to_rated, avg_rating_by_avg_time_to_rate)) +
  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='auto') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+
  ggtitle('Average rating per average number of year from release to rating')+
  labs(x='Average time in years from release date to time of rating', y='Average Rating')

avg_by_time_to_rate_model <- lm(avg_rating_by_avg_time_to_rate ~ released_to_rated, avg_rating_by_time_to_rate)
summary(avg_by_time_to_rate_model)

y_hat_avg_time_to_rate <- predict(avg_by_time_to_rate_model, 
                                  avg_rating_by_time_to_rate)

rmse_avg_time_to_rate <- sqrt(mean((y_hat_avg_time_to_rate  - 
                      avg_rating_by_time_to_rate$avg_rating_by_avg_time_to_rate)^2, 
                            na.rm = TRUE))

print(paste('The RMES is', round(rmse_avg_time_to_rate,3)))
```


### Testing the model on the validation set

We get a very similar looking plot, and a good RMSE, only slight higher than the RMSE on the test set which is what we expect. Overall, it is difficult to say what this model will in the future.  I would be interested in seeing data updated over the last 10 years and then do an average release to rating date going back 70 years.  This model goes back a max of 60 years and has an average rating of about 4.0.  With the max rating of 5, it is hard to believe the the average will get much higher than 4.  Perhaps it could go a little higher but with a shallower climb.  We see it when from about 3.4 to 4.0 in 60 years.  That is an increase of .06 every 10 years.  I don't think that could continue for much longer but if the rate where cut in half that means it increments by .09 over the next 30 years.  It is difficult to predict but the model give us better information than starting with nothing.  


```{r test the average time in years from release date to rate date, warning=FALSE, message=FALSE}

val_avg_rating_by_time_to_rate <- val1 %>% filter((released_to_rated > 0) & released_to_rated < 60) %>%
  group_by(released_to_rated) %>%
  summarize(avg_rating_by_avg_time_to_rate=mean(rating)) 


val_avg_rating_by_time_to_rate  %>% ggplot(aes(released_to_rated, avg_rating_by_avg_time_to_rate)) +
  geom_point(col='steelblue') + geom_smooth(col='red', se=FALSE, method='auto') + 
  geom_smooth(method='lm', se=FALSE, col='orange')+
  ggtitle('Validation set:  Average rating per average number of year from release to rating')+
  labs(x='Average time in years from release date to time of rating', y='Average Rating')

val_y_hat_avg_time_to_rate <- predict(avg_by_time_to_rate_model, 
                                  val_avg_rating_by_time_to_rate)

val_rmse_avg_time_to_rate <- sqrt(mean((val_y_hat_avg_time_to_rate  - 
                                      val_avg_rating_by_time_to_rate$avg_rating_by_avg_time_to_rate)^2, 
                                   na.rm = TRUE))


print(paste('The RMES on the validation set is', round(val_rmse_avg_time_to_rate,3)))
```